#!/bin/bash
echo "ğŸš€ [Pre-start] æ­£åœ¨åˆå§‹åŒ–åŒ GPU åç«¯..."

# 1. å¼ºåˆ¶å£°æ˜è·¯å¾„ä¼˜å…ˆçº§ (è§£å†³ Ollama æ‰¾ä¸åˆ° GPU)
export OLLAMA_LIBRARY_PATH="/usr/lib/ollama"
export LD_LIBRARY_PATH="/usr/lib/ollama:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:$LD_LIBRARY_PATH"
export CUDA_VISIBLE_DEVICES=0

# 2. ComfyUI æ¶æ„ä¿®å¤è¡¥ä¸
find /usr/local/lib/python3.10/dist-packages/transformers -name "*.pyc" -delete
find /comfyui -name "*.pyc" -delete
cd /comfyui && git fetch --all && git reset --hard origin/master

# 3. ä¼˜å…ˆå¯åŠ¨ Ollama å¹¶å ä½ GPU å¥æŸ„
echo "ğŸ§ª æ­£åœ¨å¯åŠ¨è§†è§‰åˆ†æå¼•æ“..."
ollama serve > /var/log/ollama.log 2>&1 &
sleep 10

# 4. å¯åŠ¨ ComfyUI ç”»å›¾å¼•æ“
echo "ğŸ¨ æ­£åœ¨å¯åŠ¨ ComfyUI..."
python /comfyui/main.py --listen 127.0.0.1 --port 8188 > /var/log/comfyui.log 2>&1 &

# 5. æœåŠ¡å¥åº·æ£€æŸ¥
python3 -c "import requests, time;
for i in range(30):
    try:
        if requests.get('http://127.0.0.1:11434/api/tags').status_code == 200 and \
           requests.get('http://127.0.0.1:8188/history').status_code == 200:
            print('âœ… æ‰€æœ‰æœåŠ¡å·²å°±ç»ªï¼'); break
    except: pass
    time.sleep(5)
"

# 6. å¯åŠ¨ä¸» Handler
python -u /comfyui/runpod_handler.py
