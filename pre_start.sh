#!/bin/bash
echo "ğŸš€ [Pre-start] æ­£åœ¨å¯åŠ¨æ•´åˆç¯å¢ƒ (Ollama GPU + ComfyUI)..."

# 1. ç¯å¢ƒå˜é‡å¼ºåˆ¶åŠ è½½ (å®Œå…¨å¤åˆ»æ˜¨æ—¥æˆåŠŸé…ç½®)
export OLLAMA_LIBRARY_PATH=/usr/lib/ollama
export LD_LIBRARY_PATH=/usr/lib/ollama:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:$LD_LIBRARY_PATH
export CUDA_VISIBLE_DEVICES=0

# 2. ComfyUI æ·±åº¦æ¶æ„ä¿®å¤ (å‚è€ƒä¿¡æ¯ 2)
find /usr/local/lib/python3.10/dist-packages/transformers -name "*.pyc" -delete
find /comfyui -name "*.pyc" -delete
cd /comfyui && git fetch --all && git reset --hard origin/master

# 3. ä¿®å¤æƒé™ä¸ç›®å½• (å‚è€ƒä¿¡æ¯ 2)
mkdir -p "/comfyui/tmp" "/comfyui/output"
chmod -R 777 "/comfyui/tmp" "/comfyui/output"
export TMPDIR="/comfyui/tmp"

# 4. å¯åŠ¨ Ollama åå°æœåŠ¡ (å®Œå…¨å¤åˆ»æ˜¨æ—¥æˆåŠŸæŒ‡ä»¤)
ollama serve > /var/log/ollama.log 2>&1 &

# 5. å¥åº·æ£€æŸ¥ï¼šç­‰å¾… Ollama å°±ç»ª (å®Œå…¨å¤åˆ»æ˜¨æ—¥æˆåŠŸæŒ‡ä»¤)
python3 -c "import requests, time; 
for i in range(30):
    try:
        r = requests.get('http://127.0.0.1:11434/api/tags')
        if r.status_code == 200:
            print('âœ… Ollama GPU æ¨¡å‹å·²å°±ç»ª'); break
    except: pass
    time.sleep(2)
"

# 6. å¯åŠ¨ ComfyUI åç«¯ (å‚è€ƒä¿¡æ¯ 1)
python /comfyui/main.py --listen 127.0.0.1 --port 8188 > /var/log/comfyui.log 2>&1 &

# 7. å¯åŠ¨ä¸»ä»»åŠ¡ç›‘å¬ (runpod_handler.py)
python -u /comfyui/runpod_handler.py
